{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8d93489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib import cm\n",
    "from torch import nn, optim\n",
    "from __future__ import annotations\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50da705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Юля\\.cache\\kagglehub\\datasets\\bloodlaac\\products-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"bloodlaac/products-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0fb0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b482bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2eb1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dir = f\"{path}\\products_dataset\"\n",
    "\n",
    "FOOD = [\n",
    "    'FreshApple', 'FreshBanana', 'FreshMango', 'FreshOrange', 'FreshStrawberry',\n",
    "    'RottenApple', 'RottenBanana', 'RottenMango', 'RottenOrange', 'RottenStrawberry',\n",
    "    'FreshBellpepper', 'FreshCarrot', 'FreshCucumber', 'FreshPotato', 'FreshTomato',\n",
    "    'RottenBellpepper', 'RottenCarrot', 'RottenCucumber', 'RottenPotato', 'RottenTomato'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c10d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledDataset():\n",
    "    def __init__(self, food_dir: Path, food_classes: list[str], transform=None) -> LabeledDataset:\n",
    "        self.food_dir = food_dir\n",
    "        self.food_classes = food_classes\n",
    "        self.transform = transform\n",
    "        self.images_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for cls_name in food_classes:\n",
    "            class_path = Path(food_dir)\n",
    "            class_path /= cls_name\n",
    "\n",
    "            for image_name in class_path.iterdir():\n",
    "                image_path = class_path / image_name\n",
    "                self.images_paths.append(image_path)\n",
    "                self.labels.append(food_classes.index(cls_name))\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        image = Image.open(self.images_paths[index]).convert(\"RGB\")\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0838caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomCrop([200, 200]),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.3, 0.3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b3856e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dataset = LabeledDataset(food_dir, FOOD, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec7fc1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(food_dataset, [0.6, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3221a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=16,\n",
    "            shuffle=True,\n",
    "            pin_memory=True  # TODO: fix\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e21b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d86527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"Create basic unit of ResNet.\n",
    "    Consists of two convolutional layers.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            stride: int = 1,\n",
    "            downsampling=None\n",
    "        ) -> Block:\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,  # TODO: Replace with padding=\"same\"\n",
    "            padding=1\n",
    "        )\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        input = x\n",
    "\n",
    "        pred = self.batch_norm(self.conv1(x))\n",
    "        pred = self.relu(pred)\n",
    "        pred = self.batch_norm(self.conv2(pred))\n",
    "        \n",
    "        if self.downsampling is not None:\n",
    "            input = self.downsampling(x)\n",
    "        \n",
    "        pred += input\n",
    "        pred = self.relu(pred)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"Build model ResNet and return prediction.\"\"\"\n",
    "\n",
    "    def __init__(self, blocks_num_list: list[int]) -> ResNet:\n",
    "        \"\"\"ResNet init.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        blocks_num_list : list[int] \n",
    "                          Number of basic blocks for each layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64  # Default number of channels for first layer. Mutable!\n",
    "\n",
    "        # Reduce resolution of picture by 2\n",
    "        # 224 -> 112\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 112 -> 56\n",
    "\n",
    "        self.layer1 = self.create_layer(  # Default stride. No resolution reduction.\n",
    "            out_channels=64,\n",
    "            num_blocks=blocks_num_list[0]\n",
    "        )\n",
    "        self.layer2 = self.create_layer(  # Resolution reduction. 56 -> 28\n",
    "            out_channels=128,\n",
    "            num_blocks=blocks_num_list[1],\n",
    "            stride=2\n",
    "        )\n",
    "        self.layer3 = self.create_layer(  # Resolution reduction. 28 -> 14\n",
    "            out_channels=256,\n",
    "            num_blocks=blocks_num_list[2],\n",
    "            stride=2\n",
    "        )\n",
    "        self.layer4 = self.create_layer(  # Resolution reduction. 14 -> 7\n",
    "            out_channels=512,\n",
    "            num_blocks=blocks_num_list[3],\n",
    "            stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 20)\n",
    "    \n",
    "    def create_layer(\n",
    "            self,\n",
    "            out_channels: int,\n",
    "            num_blocks: int,\n",
    "            stride: int = 1\n",
    "        ) -> nn.Sequential:\n",
    "        \"\"\"Create ResNet layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        out_channels : int\n",
    "            Number of output channels per block\n",
    "        num_blocks : int\n",
    "            Number of blocks per layer\n",
    "        stride : int, default=1\n",
    "            Step of filter in conv layer\n",
    "\n",
    "        \"\"\"\n",
    "        downsampling = None\n",
    "\n",
    "        if stride != 1:\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        blocks: list[Block] = []\n",
    "        \n",
    "        blocks.append(Block(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=stride,\n",
    "            downsampling=downsampling\n",
    "        ))\n",
    "\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for _ in range(num_blocks - 1):\n",
    "            blocks.append(Block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*blocks)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pred = self.batch_norm(self.conv1(x))\n",
    "        pred = self.relu(pred)\n",
    "        pred = self.pooling(pred)\n",
    "\n",
    "        pred = self.layer1(pred)\n",
    "        pred = self.layer2(pred)\n",
    "        pred = self.layer3(pred)\n",
    "        pred = self.layer4(pred)\n",
    "\n",
    "        pred = self.avgpool(pred)\n",
    "        pred = torch.flatten(pred, 1)\n",
    "        pred = self.fc(pred)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b57fffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(\n",
    "        epochs: int,\n",
    "        train_history: list,\n",
    "        val_history: list,\n",
    "        optimizer_name: str,\n",
    "        label: str\n",
    "    ):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 10))\n",
    "    ax1.plot(np.arange(1, epochs + 1), train_history, label=label)\n",
    "    ax2.plot(np.arange(1, epochs + 1), val_history, label=label)\n",
    "\n",
    "    for ax in (ax1, ax2):\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.grid(True)\n",
    "\n",
    "    ax1.set_title(f'{optimizer_name} Training accuracy')\n",
    "    ax2.set_title(f'{optimizer_name} Validation accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44e543f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(images)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "        total += len(pred)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "314bc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, val_loader, optimizer, epochs=10):\n",
    "    train_acc, val_acc = [], []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in tqdm(range(epochs), leave=False):\n",
    "        correct, total = 0, 0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(images)\n",
    "            loss = criterion(pred, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "            total += len(pred)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_acc.append(correct / total)\n",
    "        val_acc.append(validate(model, val_loader))\n",
    "        epoch_loss = train_loss / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch: [{epoch + 1}/{epochs}]\")\n",
    "        print(f\"Train accuracy: {train_acc[-1]:.4f}\")\n",
    "        print(f\"Train loss: {epoch_loss:.4f}\")\n",
    "        print(f\"Val accuracy: {val_acc[-1]:.4f}\\n\")\n",
    "\n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09d2bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(images)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "        total += len(pred)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70259e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baf63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add plotting graphs and cycle over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "679ed242",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_num_list = [2, 2, 2, 2]\n",
    "\n",
    "model = ResNet(blocks_num_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9935b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67c6e074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18 with SGD\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:53<34:32, 53.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/40]\n",
      "Train accuracy: 0.3004\n",
      "Train loss: 2.2750\n",
      "Val accuracy: 0.0725\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [01:45<33:22, 52.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/40]\n",
      "Train accuracy: 0.3418\n",
      "Train loss: 2.0926\n",
      "Val accuracy: 0.4188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [02:38<32:26, 52.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/40]\n",
      "Train accuracy: 0.4669\n",
      "Train loss: 1.6755\n",
      "Val accuracy: 0.5254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [03:30<31:30, 52.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/40]\n",
      "Train accuracy: 0.5414\n",
      "Train loss: 1.4356\n",
      "Val accuracy: 0.5700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [04:22<30:37, 52.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/40]\n",
      "Train accuracy: 0.5792\n",
      "Train loss: 1.2929\n",
      "Val accuracy: 0.6321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [05:15<29:47, 52.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6/40]\n",
      "Train accuracy: 0.6253\n",
      "Train loss: 1.1545\n",
      "Val accuracy: 0.6608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [06:08<28:54, 52.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/40]\n",
      "Train accuracy: 0.6479\n",
      "Train loss: 1.0778\n",
      "Val accuracy: 0.7033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [07:00<28:00, 52.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/40]\n",
      "Train accuracy: 0.6846\n",
      "Train loss: 0.9805\n",
      "Val accuracy: 0.6975\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [07:52<27:06, 52.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/40]\n",
      "Train accuracy: 0.7011\n",
      "Train loss: 0.9038\n",
      "Val accuracy: 0.7233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [08:45<26:14, 52.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10/40]\n",
      "Train accuracy: 0.7224\n",
      "Train loss: 0.8506\n",
      "Val accuracy: 0.7096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [09:37<25:21, 52.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11/40]\n",
      "Train accuracy: 0.7472\n",
      "Train loss: 0.7795\n",
      "Val accuracy: 0.7412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [10:30<24:31, 52.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12/40]\n",
      "Train accuracy: 0.7550\n",
      "Train loss: 0.7579\n",
      "Val accuracy: 0.7262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [11:23<23:39, 52.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13/40]\n",
      "Train accuracy: 0.7660\n",
      "Train loss: 0.7011\n",
      "Val accuracy: 0.7592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [12:15<22:45, 52.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14/40]\n",
      "Train accuracy: 0.7771\n",
      "Train loss: 0.6754\n",
      "Val accuracy: 0.7521\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [13:08<21:52, 52.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15/40]\n",
      "Train accuracy: 0.7885\n",
      "Train loss: 0.6382\n",
      "Val accuracy: 0.7750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [14:00<20:59, 52.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16/40]\n",
      "Train accuracy: 0.7937\n",
      "Train loss: 0.6223\n",
      "Val accuracy: 0.7058\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [14:52<20:06, 52.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17/40]\n",
      "Train accuracy: 0.8015\n",
      "Train loss: 0.6107\n",
      "Val accuracy: 0.8008\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [15:45<19:13, 52.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18/40]\n",
      "Train accuracy: 0.8074\n",
      "Train loss: 0.5999\n",
      "Val accuracy: 0.7571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [16:37<18:20, 52.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19/40]\n",
      "Train accuracy: 0.8124\n",
      "Train loss: 0.5657\n",
      "Val accuracy: 0.7796\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [17:30<17:29, 52.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20/40]\n",
      "Train accuracy: 0.8208\n",
      "Train loss: 0.5402\n",
      "Val accuracy: 0.8192\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [18:22<16:36, 52.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21/40]\n",
      "Train accuracy: 0.8307\n",
      "Train loss: 0.4985\n",
      "Val accuracy: 0.8129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [19:14<15:42, 52.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [22/40]\n",
      "Train accuracy: 0.8315\n",
      "Train loss: 0.4978\n",
      "Val accuracy: 0.7817\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [20:07<14:52, 52.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23/40]\n",
      "Train accuracy: 0.8432\n",
      "Train loss: 0.4699\n",
      "Val accuracy: 0.8233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [20:59<13:59, 52.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24/40]\n",
      "Train accuracy: 0.8469\n",
      "Train loss: 0.4621\n",
      "Val accuracy: 0.8146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [21:52<13:07, 52.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25/40]\n",
      "Train accuracy: 0.8535\n",
      "Train loss: 0.4417\n",
      "Val accuracy: 0.8375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [22:44<12:13, 52.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [26/40]\n",
      "Train accuracy: 0.8571\n",
      "Train loss: 0.4197\n",
      "Val accuracy: 0.8300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [23:37<11:21, 52.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27/40]\n",
      "Train accuracy: 0.8617\n",
      "Train loss: 0.4117\n",
      "Val accuracy: 0.8229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [24:29<10:29, 52.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [28/40]\n",
      "Train accuracy: 0.8635\n",
      "Train loss: 0.4153\n",
      "Val accuracy: 0.8329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [25:21<09:36, 52.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [29/40]\n",
      "Train accuracy: 0.8699\n",
      "Train loss: 0.3892\n",
      "Val accuracy: 0.7954\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [26:14<08:43, 52.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30/40]\n",
      "Train accuracy: 0.8754\n",
      "Train loss: 0.3772\n",
      "Val accuracy: 0.8200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [27:06<07:51, 52.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [31/40]\n",
      "Train accuracy: 0.8803\n",
      "Train loss: 0.3509\n",
      "Val accuracy: 0.8367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [27:59<06:59, 52.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32/40]\n",
      "Train accuracy: 0.8735\n",
      "Train loss: 0.3779\n",
      "Val accuracy: 0.8429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [28:51<06:06, 52.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [33/40]\n",
      "Train accuracy: 0.8886\n",
      "Train loss: 0.3344\n",
      "Val accuracy: 0.8492\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [29:43<05:14, 52.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [34/40]\n",
      "Train accuracy: 0.8860\n",
      "Train loss: 0.3417\n",
      "Val accuracy: 0.8321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [30:36<04:21, 52.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35/40]\n",
      "Train accuracy: 0.8862\n",
      "Train loss: 0.3275\n",
      "Val accuracy: 0.8529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [31:28<03:29, 52.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [36/40]\n",
      "Train accuracy: 0.8892\n",
      "Train loss: 0.3280\n",
      "Val accuracy: 0.8638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [32:20<02:37, 52.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [37/40]\n",
      "Train accuracy: 0.9022\n",
      "Train loss: 0.2932\n",
      "Val accuracy: 0.8608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [33:13<01:44, 52.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38/40]\n",
      "Train accuracy: 0.8929\n",
      "Train loss: 0.3164\n",
      "Val accuracy: 0.8625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [34:05<00:52, 52.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [39/40]\n",
      "Train accuracy: 0.9011\n",
      "Train loss: 0.2841\n",
      "Val accuracy: 0.8579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [40/40]\n",
      "Train accuracy: 0.9051\n",
      "Train loss: 0.2781\n",
      "Val accuracy: 0.8829\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8888\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training ResNet18 with SGD\\n\")\n",
    "    \n",
    "train_acc, val_acc = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=40\n",
    ")\n",
    "\n",
    "test_acc = test(model, test_dataloader)\n",
    "\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sniffnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
