{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8d93489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from matplotlib import cm\n",
    "from torch import nn, optim\n",
    "from __future__ import annotations\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50da705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Юля\\.cache\\kagglehub\\datasets\\bloodlaac\\products-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"bloodlaac/products-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0fb0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b482bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2eb1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dir = f\"{path}\\products_dataset\"\n",
    "\n",
    "FOOD = [\n",
    "    'FreshApple', 'FreshBanana', 'FreshMango', 'FreshOrange', 'FreshStrawberry',\n",
    "    'RottenApple', 'RottenBanana', 'RottenMango', 'RottenOrange', 'RottenStrawberry',\n",
    "    'FreshBellpepper', 'FreshCarrot', 'FreshCucumber', 'FreshPotato', 'FreshTomato',\n",
    "    'RottenBellpepper', 'RottenCarrot', 'RottenCucumber', 'RottenPotato', 'RottenTomato'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c10d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledDataset():\n",
    "    def __init__(self, food_dir: Path, food_classes: list[str], transform=None) -> LabeledDataset:\n",
    "        self.food_dir = food_dir\n",
    "        self.food_classes = food_classes\n",
    "        self.transform = transform\n",
    "        self.images_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for cls_name in food_classes:\n",
    "            class_path = Path(food_dir)\n",
    "            class_path /= cls_name\n",
    "\n",
    "            for image_name in class_path.iterdir():\n",
    "                image_path = class_path / image_name\n",
    "                self.images_paths.append(image_path)\n",
    "                self.labels.append(food_classes.index(cls_name))\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        image = Image.open(self.images_paths[index]).convert(\"RGB\")\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0838caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomCrop([200, 200]),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.3, 0.3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b3856e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dataset = LabeledDataset(food_dir, FOOD, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec7fc1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(food_dataset, [0.6, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3221a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=16,\n",
    "            shuffle=True,\n",
    "            pin_memory=True  # TODO: fix\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e21b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87d86527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    Create basic unit of ResNet.\n",
    "\n",
    "    Consists of two convolutional layers.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            stride: int = 1,\n",
    "            downsampling=None\n",
    "        ) -> Block:\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,  # TODO: Replace with padding=\"same\"\n",
    "            padding=1\n",
    "        )\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        input = x\n",
    "\n",
    "        pred = self.batch_norm(self.conv1(x))\n",
    "        pred = self.relu(pred)\n",
    "        pred = self.batch_norm(self.conv2(pred))\n",
    "        \n",
    "        if self.downsampling is not None:\n",
    "            input = self.downsampling(x)\n",
    "        \n",
    "        pred += input\n",
    "        pred = self.relu(pred)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c0e0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Build model ResNet and return prediction\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_num_list: list[int]) -> ResNet:\n",
    "        \"\"\"\n",
    "        ResNet init.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        blocks_num_list : list[int] \n",
    "                          Number of basic blocks for each layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64  # Default number of channels for first layer. Mutable!\n",
    "\n",
    "        # Reduce resolution of picture by 2\n",
    "        # 224 -> 112\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3\n",
    "        )\n",
    "        self.batch_norm = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 112 -> 56\n",
    "\n",
    "        self.layer1 = self.create_layer(  # Default stride. No resolution reduction.\n",
    "            out_channels=64,\n",
    "            num_blocks=blocks_num_list[0]\n",
    "        )\n",
    "        self.layer2 = self.create_layer(  # Resolution reduction. 56 -> 28\n",
    "            out_channels=128,\n",
    "            num_blocks=blocks_num_list[1],\n",
    "            stride=2\n",
    "        )\n",
    "        self.layer3 = self.create_layer(  # Resolution reduction. 28 -> 14\n",
    "            out_channels=256,\n",
    "            num_blocks=blocks_num_list[2],\n",
    "            stride=2\n",
    "        )\n",
    "        self.layer4 = self.create_layer(  # Resolution reduction. 14 -> 7\n",
    "            out_channels=512,\n",
    "            num_blocks=blocks_num_list[3],\n",
    "            stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 20)\n",
    "    \n",
    "    def create_layer(\n",
    "            self,\n",
    "            out_channels: int,\n",
    "            num_blocks: int,\n",
    "            stride: int = 1\n",
    "        ) -> nn.Sequential:\n",
    "        \"\"\"\n",
    "        Create ResNet layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        out_channels : int\n",
    "            Number of output channels per block\n",
    "        num_blocks : int\n",
    "            Number of blocks per layer\n",
    "        stride : int, default=1\n",
    "            Step of filter in conv layer\n",
    "\n",
    "        \"\"\"\n",
    "        downsampling = None\n",
    "\n",
    "        if stride != 1:\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        blocks: list[Block] = []\n",
    "        \n",
    "        blocks.append(Block(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=out_channels,\n",
    "            stride=stride,\n",
    "            downsampling=downsampling\n",
    "        ))\n",
    "\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for _ in range(num_blocks - 1):\n",
    "            blocks.append(Block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*blocks)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pred = self.batch_norm(self.conv1(x))\n",
    "        pred = self.relu(pred)\n",
    "        pred = self.pooling(pred)\n",
    "\n",
    "        pred = self.layer1(pred)\n",
    "        pred = self.layer2(pred)\n",
    "        pred = self.layer3(pred)\n",
    "        pred = self.layer4(pred)\n",
    "\n",
    "        pred = self.avgpool(pred)\n",
    "        pred = torch.flatten(pred, 1)\n",
    "        pred = self.fc(pred)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b57fffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(\n",
    "        epochs: int,\n",
    "        train_history: list,\n",
    "        val_history: list,\n",
    "        optimizer_name: str,\n",
    "        label: str\n",
    "    ):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 10))\n",
    "    ax1.plot(np.arange(1, epochs + 1), train_history, label=label)\n",
    "    ax2.plot(np.arange(1, epochs + 1), val_history, label=label)\n",
    "\n",
    "    for ax in (ax1, ax2):\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Accuracy')\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.grid(True)\n",
    "\n",
    "    ax1.set_title(f'{optimizer_name} Training accuracy')\n",
    "    ax2.set_title(f'{optimizer_name} Validation accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44e543f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(images)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "        total += len(pred)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "314bc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, val_loader, optimizer, epochs=10):\n",
    "    train_acc, val_acc = [], []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in tqdm(range(epochs), leave=False):\n",
    "        correct, total = 0, 0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(images)\n",
    "            loss = criterion(pred, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "            total += len(pred)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_acc.append(correct / total)\n",
    "        val_acc.append(validate(model, val_loader))\n",
    "        epoch_loss = train_loss / len(train_loader)\n",
    "\n",
    "        print(f\"Epoch: [{epoch + 1}/{epochs}]\")\n",
    "        print(f\"Train accuracy: {train_acc[-1]:.4f}\")\n",
    "        print(f\"Train loss: {epoch_loss:.4f}\")\n",
    "        print(f\"Val accuracy: {val_acc[-1]:.4f}\\n\")\n",
    "\n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09d2bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(images)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "        total += len(pred)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70259e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfdd7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_num_list = [2, 2, 2, 2]\n",
    "\n",
    "model = ResNet(blocks_num_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7478a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "baf63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add plotting graphs and cycle over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a97017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18 with SGD\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:56<17:49, 56.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/20]\n",
      "Train accuracy: 0.5521\n",
      "Train loss: 1.3687\n",
      "Val accuracy: 0.4933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:51<16:45, 55.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/20]\n",
      "Train accuracy: 0.6071\n",
      "Train loss: 1.2162\n",
      "Val accuracy: 0.6600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:47<15:47, 55.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/20]\n",
      "Train accuracy: 0.6400\n",
      "Train loss: 1.1028\n",
      "Val accuracy: 0.6150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [03:42<14:49, 55.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/20]\n",
      "Train accuracy: 0.6721\n",
      "Train loss: 0.9964\n",
      "Val accuracy: 0.6404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [04:38<13:52, 55.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/20]\n",
      "Train accuracy: 0.6929\n",
      "Train loss: 0.9442\n",
      "Val accuracy: 0.6958\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [05:33<12:56, 55.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6/20]\n",
      "Train accuracy: 0.7265\n",
      "Train loss: 0.8412\n",
      "Val accuracy: 0.7379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [06:28<12:00, 55.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/20]\n",
      "Train accuracy: 0.7328\n",
      "Train loss: 0.8069\n",
      "Val accuracy: 0.6837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [07:22<10:59, 54.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/20]\n",
      "Train accuracy: 0.7432\n",
      "Train loss: 0.7781\n",
      "Val accuracy: 0.7488\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [08:17<10:02, 54.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/20]\n",
      "Train accuracy: 0.7631\n",
      "Train loss: 0.7262\n",
      "Val accuracy: 0.7262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [09:11<09:06, 54.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10/20]\n",
      "Train accuracy: 0.7700\n",
      "Train loss: 0.6820\n",
      "Val accuracy: 0.7775\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [10:06<08:11, 54.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11/20]\n",
      "Train accuracy: 0.7832\n",
      "Train loss: 0.6703\n",
      "Val accuracy: 0.7858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [11:00<07:15, 54.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12/20]\n",
      "Train accuracy: 0.7889\n",
      "Train loss: 0.6500\n",
      "Val accuracy: 0.7846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [11:54<06:21, 54.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13/20]\n",
      "Train accuracy: 0.7935\n",
      "Train loss: 0.6318\n",
      "Val accuracy: 0.7925\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [12:48<05:26, 54.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14/20]\n",
      "Train accuracy: 0.7979\n",
      "Train loss: 0.6054\n",
      "Val accuracy: 0.8117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [13:43<04:31, 54.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15/20]\n",
      "Train accuracy: 0.8122\n",
      "Train loss: 0.5653\n",
      "Val accuracy: 0.7987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [14:37<03:36, 54.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [16/20]\n",
      "Train accuracy: 0.8136\n",
      "Train loss: 0.5617\n",
      "Val accuracy: 0.7992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [15:31<02:42, 54.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17/20]\n",
      "Train accuracy: 0.8263\n",
      "Train loss: 0.5256\n",
      "Val accuracy: 0.8221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [16:25<01:48, 54.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18/20]\n",
      "Train accuracy: 0.8336\n",
      "Train loss: 0.5009\n",
      "Val accuracy: 0.8025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [17:20<00:54, 54.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19/20]\n",
      "Train accuracy: 0.8343\n",
      "Train loss: 0.5024\n",
      "Val accuracy: 0.8208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20/20]\n",
      "Train accuracy: 0.8462\n",
      "Train loss: 0.4713\n",
      "Val accuracy: 0.8154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.8108\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training ResNet18 with SGD\\n\")\n",
    "    \n",
    "train_acc, val_acc = train(\n",
    "    model,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "test_acc = test(model, test_dataloader)\n",
    "\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
